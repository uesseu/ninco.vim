*ninco.vim.txt*	  ChatGPT and some compatible API on vim.

Author: Shoichiro Nakanishi <sheepwing@kyudai.jp>
License: MIT license

==============================================================================
CONTENTS                                                        *slide-contents*

Introduction		|ninco-introduction|
Requirements  	 	|ninco-requirements|
Basic usage  	 	|ninco-template|
Configuration  	 	|ninco-configuration|
Usage	  	 	|ninco-usage|
Example	  	 	|ninco-example|
Openai compatible API  	|ninco-api|
Model setting		|ninco-model|

==============================================================================
INTRODUCTION                                                *ninco-introduction*
# What is this?
ChatGPT compatible client for vim and neovim written in typescript by denops.

It is still under developping and destructive change may be done.
It is just for my daily life, work and hobby.

# Features of ninco.vim
Good and bad point of ninco.vim is simplicity and cheapness.
However, I use it in daily life and it is useful for me. It can...

- Ask a simple question
- Ask a question of selected lines
- Talk with chatgpt, compressing old data
- Not only chatgpt of openai but also compatible servers
- Ask using templates

==============================================================================
Requirements                                    *ninco-requirements*

Vim or neovim, Denops and API key of openai is also needed.
About library, it depends only on denops and so please see the requirements of denops.


==============================================================================
Template                                               *ninco-template*

At first, make template. Now, I make text file named 'temlpalte.md'.

markdown: >
  Hello %s!
<
%s is variable. Of cource, multiple variables can be used.
Then...

Ninco()                                             |Ninco()|
>
  :call Ninco("template.md", "world")
<

This code sends openai 'Hello world!' and prints reply.
If the first argument is blank string, no templates will be used and
just second argument will be sent to openai.

However, you must write vimrc to use it. ;-(
Please read below.

==============================================================================
Configuration  	 	                    |ninco-configuration|

If you want to use this plugin, at least, you should configure vimrc.

g:ninco#single                            |g:ninco#single|
If global variable named 'g:ninco#single' is 1,
log will be made and chatgpt looks remebmers your words.
If global variable named 'g:ninco#single' is 0,
log will not be made and the fee will be cheap.
Default is 0.
>
  let g:ninco#single = 1
<

g:ninco#max_log                                   |g:ninco#max_log|
g:ninco#min_log                                   |g:ninco#max_log|

If g:ninco#single is 1 and g:ninco#max_log is not 0,
auto compress is enabled.

If log is bigger than g:ninco#max_log, auto talk log compression
is enabled. The size of talk log will be compressed to
be g:ninco#min_log.
Bellow is the default.

 >
  let g:ninco#max_log = 20
  let g:ninco#min_log = 10
<

Enable ninco                                         |NincoEnable()|

This function enables ninco. >
  call NincoEnable([API_KEY],
      \'gpt-3.5-turbo',
      \"https://api.openai.com/v1/chat/completions")
<

Enable ninco                                         |NincoEnableWindow()|

If you want to make new window, you can call this function. >
  call NincoEnableWindow([API_KEY],
      \'gpt-3.5-turbo',
      \"https://api.openai.com/v1/chat/completions"
      \0)
<
If last argument is 0, window is divided horizontally.
If it is 1, vertical one is used.
The functions has default argument and if you do not want to configure,
only API_KEY is needed.


g:ninco#async_cmd_win                            |g:ninco#async_cmd_win|

If you want to change the name of window, you can set this global variable. >
  let g:ninco#async_cmd_win = '__CHATGPT__'
<

==============================================================================
Example  	 	                    |ninco-example|
This is part of my vimrc.

This codes enables...
- Start Ninco by '\\c' or '\\d'
- Compress talklog by 'gc'
- Use Ninco by 'gn'

 >
  let g:ninco#single = 1
  let g:api_key = "[API_KEY]"
  let g:ninco#gpt_model = "gpt-3.5-turbo"
  let g:ninco#gpt_url = "https://api.openai.com/v1/chat/completions"

  nnoremap <leader>d :call NincoEnableWindow(g:api_key, g:ninco#gpt_model, g:ninco#gpt_url)<CR>
  nnoremap <leader>c :call NincoEnable(g:api_key, g:ninco#gpt_model, g:ninco#gpt_url)<CR>

  " Compress log
  nnoremap gc :call NincoCompress(5)

  " Normal mode
  nnoremap gn :call Ninco("", "")<C-F>04f"<C-C>

  " Visual mode
  vnoremap gn :<C-E><C-U>call Ninco("", "", GetVisualSelection())<C-F>04f"<C-C>
<
==============================================================================
Openai compatible local server                          *ninco-api*
If you want to use openai compatible server on localhost,
you need not use api_key and model. Just use blank string.
And you should set url.
 >
  let g:api_key = "[API_KEY]"
  let g:ninco#gpt_model = "gpt-3.5-turbo"
  let g:ninco#gpt_url = "http://127.0.0.1:8000/v1/chat/completions"
  call NincoEnable(g:api_key, g:ninco#gpt_model, g:ninco#gpt_url)
<

You can make compatible server by text-generation-webui.
https://github.com/oobabooga/text-generation-webui
Using this, you can use it in offline environment easily.

==============================================================================
# Model setting                                             *ninco-model*

If you want to change model after enabling ninco, NincoSetModel may be useful.
It may be only for openai.
 >
  call NincoSetModel('gpt-3.5-turbo')
<
==============================================================================
vim:tw=78:ts=8:ft=help:norl:noet:fen:noet:
